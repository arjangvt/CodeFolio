{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stemming.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM59bIWM1letaTKBw1xI//u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arjangvt/CodeFolio/blob/main/ML/NLP/Basics/Stemming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I use NLTK for basic text and language process.\n",
        "I use these examples as my own references.\n",
        "\n",
        "Note:\n",
        "Typically if you install nltk on your personal computer, you don't need to install each package separately (See NLTK installation colab file). Since Colab does not hold the installation we have to install nesessary packages separately.\n",
        "Written by: Arjang Fahim Date: 3/19/2018"
      ],
      "metadata": {
        "id": "fa6LolZtFwHK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stemming"
      ],
      "metadata": {
        "id": "J_Cdj-anFuDj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xw2aO1BtD6Nz",
        "outputId": "31b5598c-d98e-4812-f3db-f563c347f6c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing dataset\n",
        "dataset = ['love', 'loving', 'lover', 'loved', 'lovingly']"
      ],
      "metadata": {
        "id": "Ib4wWlaVF89o"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply stemming\n",
        "ps = PorterStemmer()\n",
        "for word in dataset:\n",
        "    print(ps.stem(word=word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvcQXWAuGCBV",
        "outputId": "a0984762-8110-41d3-b236-172bd5cde453"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "love\n",
            "love\n",
            "lover\n",
            "love\n",
            "lovingli\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_dataset = \"\"\" It feels very special when you are loving someone.\n",
        "                  we care for our loved ones.\n",
        "                  Specially when we love each other unconditionally\n",
        "              \"\"\""
      ],
      "metadata": {
        "id": "j2SoV8fWGDLP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = word_tokenize(text=new_dataset)"
      ],
      "metadata": {
        "id": "E-yjDe7nGIOG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "    print(ps.stem(word=word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlK3-wTlGO25",
        "outputId": "ee10a507-d31c-4ad1-9e9b-59dd1ae707d0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It\n",
            "feel\n",
            "veri\n",
            "special\n",
            "when\n",
            "you\n",
            "are\n",
            "love\n",
            "someon\n",
            ".\n",
            "we\n",
            "care\n",
            "for\n",
            "our\n",
            "love\n",
            "one\n",
            ".\n",
            "special\n",
            "when\n",
            "we\n",
            "love\n",
            "each\n",
            "other\n",
            "uncondit\n"
          ]
        }
      ]
    }
  ]
}